{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation\n",
    "\n",
    "Wherein we take the model as trained and tuned on the full training set and check it against the hold-out test set split off at the beginning of development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "train_conn = sqlite3.connect('./sqlite/training_incidents.sqlite')\n",
    "test_conn  = sqlite3.connect('./sqlite/validation_incidents.sqlite')\n",
    "\n",
    "r_seed = 38\n",
    "\n",
    "train_inputs = []\n",
    "train_labels = []\n",
    "test_inputs = []\n",
    "test_labels = []\n",
    "\n",
    "train_results = train_conn.execute(\"SELECT * from incidents\")\n",
    "test_results = test_conn.execute(\"SELECT * from incidents\")\n",
    "\n",
    "for rec in train_results:\n",
    "    train_labels.append(rec[1])\n",
    "    train_inputs.append(rec[2:])\n",
    "\n",
    "for rec in test_results:\n",
    "    test_labels.append(rec[1])\n",
    "    test_inputs.append(rec[2:])\n",
    "\n",
    "\n",
    "inputs_train = np.array(train_inputs)\n",
    "inputs_test = np.array(test_inputs)\n",
    "labels_train = np.array(train_labels)\n",
    "labels_test = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point all the data is loaded, both training and test, so now we take the parameters\n",
    "from the tuned algorithm and train it on the full set before scoring it against the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVS 0.640268570775\n",
      "MAE 0.839164971066\n",
      "MSE 1.5930784843\n",
      "MedAE 0.534785447124\n",
      "r^2 0.640263108594\n",
      "[ 0.00420535  0.00673082  0.00572975  0.0068716   0.01373218  0.00204348\n",
      "  0.0198523   0.03353582  0.0133058   0.0095292   0.00923145  0.00923595\n",
      "  0.00125699  0.0011511   0.00262994  0.00352596  0.          0.00515529\n",
      "  0.04151542  0.20061566  0.04990149  0.05841704  0.29183182  0.00475986\n",
      "  0.          0.          0.00112327  0.          0.00082123  0.          0.\n",
      "  0.00080877  0.00429323  0.00106518  0.          0.00356953  0.00655799\n",
      "  0.00240636  0.01228248  0.00599683  0.02701666  0.01698954  0.00385986\n",
      "  0.00567016  0.00350229  0.01129049  0.00268853  0.00172596  0.00278653\n",
      "  0.00333687  0.00410317  0.          0.00251664  0.00362095  0.00164701\n",
      "  0.00124087  0.05934776  0.0052449   0.00787634  0.00184634  0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr_clf = GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=1.0, loss='ls',\n",
    "             max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "             min_samples_leaf=5, min_samples_split=5,\n",
    "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "             warm_start=False)\n",
    "\n",
    "gbr_clf.fit(inputs_train, labels_train)\n",
    "\n",
    "labels_predict = gbr_clf.predict(inputs_test)\n",
    "\n",
    "print \"EVS\", explained_variance_score(labels_test, labels_predict)\n",
    "print \"MAE\", mean_absolute_error(labels_test, labels_predict)\n",
    "print \"MSE\", mean_squared_error(labels_test, labels_predict)\n",
    "print \"MedAE\", median_absolute_error(labels_test, labels_predict)\n",
    "print \"r^2\", r2_score(labels_test, labels_predict)\n",
    "print gbr_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite promising; here I'm showing an r^2 score of 0.64 against a quite large dataset (30k) that has never been seen by the model before either in training or tuning.  The next step is to persist it so it can be incorporated into other programs without paying a retraining penalty.  This is where we'll check the benchmark for correct record order greater than 75% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "CORRECT 84, AVG DELTA 11276.3690476\n",
      "INCORRECT 16, AVG DELTA 6631.25\n",
      "------------\n",
      "TRIAL 2\n",
      "CORRECT 76, AVG DELTA 13588.9605263\n",
      "INCORRECT 24, AVG DELTA 4934.04166667\n",
      "------------\n",
      "TRIAL 3\n",
      "CORRECT 83, AVG DELTA 16471.9156627\n",
      "INCORRECT 17, AVG DELTA 7952.88235294\n",
      "------------\n",
      "TRIAL 4\n",
      "CORRECT 85, AVG DELTA 14023.7647059\n",
      "INCORRECT 15, AVG DELTA 5026.66666667\n",
      "------------\n",
      "TRIAL 5\n",
      "CORRECT 81, AVG DELTA 14575.6790123\n",
      "INCORRECT 19, AVG DELTA 7829.68421053\n",
      "------------\n",
      "TRIAL 6\n",
      "CORRECT 81, AVG DELTA 15550.7777778\n",
      "INCORRECT 19, AVG DELTA 5907.89473684\n",
      "------------\n",
      "TRIAL 7\n",
      "CORRECT 81, AVG DELTA 14842.0864198\n",
      "INCORRECT 19, AVG DELTA 7233.21052632\n",
      "------------\n",
      "TRIAL 8\n",
      "CORRECT 84, AVG DELTA 12543.3690476\n",
      "INCORRECT 16, AVG DELTA 7277.8125\n",
      "------------\n",
      "TRIAL 9\n",
      "CORRECT 84, AVG DELTA 10724.702381\n",
      "INCORRECT 16, AVG DELTA 7703.0625\n",
      "------------\n",
      "TRIAL 10\n",
      "CORRECT 85, AVG DELTA 13098.0117647\n",
      "INCORRECT 15, AVG DELTA 7410.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "for trial in range(10):\n",
    "    correct_order_count = 0\n",
    "    incorrect_order_count = 0\n",
    "    actual_difference_correct = []\n",
    "    actual_differences_incorrect = []\n",
    "    for i in range(100):\n",
    "        index1 = random.randint(0,len(inputs_test)-1) \n",
    "        index2 = random.randint(0,len(inputs_test)-1) \n",
    "        inputs = [inputs_test[index1], inputs_test[index2]]\n",
    "        labels = [labels_test[index1], labels_test[index2]]\n",
    "        predictions = gbr_clf.predict(inputs)\n",
    "        delta = math.fabs(math.exp(labels[0]) - math.exp(labels[1]))\n",
    "        if labels[0] > labels[1]:\n",
    "            if predictions[0] > predictions[1]:\n",
    "                correct_order_count += 1\n",
    "                actual_difference_correct.append(delta)\n",
    "            else:\n",
    "                incorrect_order_count += 1\n",
    "                actual_differences_incorrect.append(delta)\n",
    "        else:\n",
    "            if predictions[0] > predictions[1]:\n",
    "                incorrect_order_count += 1\n",
    "                actual_differences_incorrect.append(delta)\n",
    "            else:\n",
    "                correct_order_count += 1\n",
    "                actual_difference_correct.append(delta)\n",
    "\n",
    "    print \"TRIAL %s\" % (trial + 1)\n",
    "    print \"CORRECT %s, AVG DELTA %s\" % (correct_order_count, sum(actual_difference_correct)/len(actual_difference_correct))\n",
    "    print \"INCORRECT %s, AVG DELTA %s\" % (incorrect_order_count, sum(actual_differences_incorrect)/len(actual_differences_incorrect))\n",
    "    print \"------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(gbr_clf, open('final_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
