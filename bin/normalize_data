#!/usr/bin/env python

import os
import sys
import dataset
import math
from collections import OrderedDict
from lib import nfirs_features

if not os.path.isfile("./sqlite/normalized_incidents.sqlite"):
    if not os.path.isfile("./sqlite/clean_incidents.sqlite"):
        print "Oops, clean incidents sqlite file doesn't exist, run \"clean_data\" script"
        sys.exit()
    print "normalized incidents file missing, creating from clean incidents..."

    clean_db = dataset.connect('sqlite:///./sqlite/clean_incidents.sqlite')
    normalized_db = dataset.connect('sqlite:///./sqlite/normalized_incidents.sqlite')

    input_table = clean_db['incidents']
    output_table = normalized_db['incidents']

    set = "normalize-data"
    i = 0
    # about 215k
    for clean_rec in input_table:
        normalized_rec = OrderedDict()
        normalized_rec["PROP_LOSS"] = math.log(clean_rec["PROP_LOSS"])
        normalized_rec = nfirs_features.normalize_features(clean_rec, normalized_rec)
         # fix skew
        # Property Use and Not Residential and AREA_ORIGIN are no longer diverse,
        # excluding them from the final dataset
        output_table.insert(normalized_rec)


        i += 1
        print set + "" + str(i)


else:
    print "normalized incidents file already exists"

print "Done!"
